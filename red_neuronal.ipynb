{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proyecto consiste en construir una red neuronal desde cero usando solo NumPy para clasificar im谩genes de prendas de ropa en el dataset Fashion MNIST.\n",
    "\n",
    " Objetivo del Proyecto\n",
    "- Implementar una red neuronal simple con NumPy.\n",
    "- Clasificar im谩genes del conjunto de datos Fashion MNIST .\n",
    "- Aplicar t茅cnicas como pase hacia adelante, funciones de activaci贸n, c谩lculo de p茅rdida y retropropagaci贸n.\n",
    "- Evitar el sobreajuste y mejorar el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Importaci贸n de Librer铆as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import fetch_openml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las librer铆as necesarias:\n",
    "- numpy para operaciones num茅ricas.\n",
    "- matplotlib para visualizaci贸n.\n",
    "- sklearn para manipulaci贸n de datos y preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Carga de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza fetch_openml para cargar el dataset Fashion MNIST, que contiene im谩genes de art铆culos de ropa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset Fashion MNIST\n",
    "fashion_mnist = fetch_openml(\"fashion-mnist\", version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Preprocesamiento de Datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalizaci贸n de las im谩genes dividiendo por 255 para que los valores est茅n entre 0 y 1.\n",
    "- Conversi贸n de las etiquetas a enteros y luego a un array de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "X = fashion_mnist.data / 255.0  # Normalizar los pixeles\n",
    "y = fashion_mnist.target.astype(int).values  # Convertir las etiquetas a enteros y convertir a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Codificaci贸n de las etiquetas en formato One-Hot utilizando OneHotEncoder.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar las etiquetas en formato One-Hot\n",
    "#Esto convierte las etiquetas en vectores binarios donde solo una posici贸n es 1 (la clase correcta)\n",
    "encoder = OneHotEncoder(sparse_output=False)  \n",
    "y_one_hot = encoder.fit_transform(y.reshape(-1, 1))  # Reshaping para que sea una matriz columna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Divisi贸n de Datos:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Divisi贸n del dataset en conjuntos de entrenamiento y prueba utilizando train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se imprimen las dimensiones de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de X_train: (56000, 784)\n",
      "Dimensiones de y_train: (56000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Verificar las dimensiones de los datos cargados\n",
    "print(\"Dimensiones de X_train:\", X_train.shape) # xxim谩genes, cada una con xx p铆xeles\n",
    "print(\"Dimensiones de y_train:\", y_train.shape) # xx etiquetas en formato One-Hot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Funciones de la Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementaci贸n de funciones de activaci贸n (relu y softmax) y sus derivadas.\n",
    "- Inicializaci贸n de los pesos y sesgos de la red neuronal.\n",
    "- Implementaci贸n del pase hacia adelante (forward_pass) y la funci贸n de p茅rdida (cross-entropy).\n",
    "- Implementaci贸n del algoritmo de retropropagaci贸n (backpropagation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n de activaci贸n ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Derivada de ReLU\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(int)\n",
    "\n",
    "# Funci贸n de activaci贸n Softmax para la capa de salida\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Derivada de Softmax\n",
    "def softmax_derivative(x):\n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros\n",
    "\n",
    "# Inicializaci贸n de los pesos y sesgos\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    W1 = np.random.randn(input_size, hidden_size) * 0.01  # Pesos de la capa de entrada a la capa oculta\n",
    "    b1 = np.zeros((1, hidden_size))  # Sesgos de la capa oculta\n",
    "    W2 = np.random.randn(hidden_size, output_size) * 0.01  # Pesos de la capa oculta a la capa de salida\n",
    "    b2 = np.zeros((1, output_size))  # Sesgos de la capa de salida\n",
    "    return W1, b1, W2, b2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward y perdida\n",
    "# Forward Pass\n",
    "def forward_pass(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = relu(Z1)  # Activaci贸n de la capa oculta\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = softmax(Z2)  # Activaci贸n de la capa de salida\n",
    "    return A1, A2\n",
    "\n",
    "# Funci贸n de p茅rdida (Cross-entropy)\n",
    "def compute_loss(y, A2):\n",
    "    m = y.shape[0]  # N煤mero de muestras\n",
    "    log_likelihood = -np.log(A2[range(m), np.argmax(y, axis=1)])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "\n",
    "def backpropagation(X, y, A1, A2, W1, W2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Derivadas\n",
    "    dZ2 = A2 - y  # Error en la capa de salida\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    \n",
    "    dZ1 = np.dot(dZ2, W2.T) * relu_derivative(A1)  # Error en la capa oculta\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "    \n",
    "    return dW1, db1, dW2, db2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Entrenamiento de la Red:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrenamiento de la red neuronal durante un n煤mero definido de 茅pocas.\n",
    "- Actualizaci贸n de los par谩metros (pesos y sesgos) utilizando el algoritmo de retropropagaci贸n.\n",
    "- Impresi贸n de la p茅rdida cada 100 茅pocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de la red\n",
    "def train(X_train, y_train, input_size, hidden_size, output_size, epochs, learning_rate):\n",
    "    W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, output_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        A1, A2 = forward_pass(X_train, W1, b1, W2, b2)\n",
    "        \n",
    "        # C谩lculo de la p茅rdida\n",
    "        loss = compute_loss(y_train, A2)\n",
    "        \n",
    "        # Backpropagation\n",
    "        dW1, db1, dW2, db2 = backpropagation(X_train, y_train, A1, A2, W1, W2)\n",
    "        \n",
    "        # Actualizaci贸n de par谩metros\n",
    "        W1 -= learning_rate * dW1\n",
    "        b1 -= learning_rate * db1\n",
    "        W2 -= learning_rate * dW2\n",
    "        b2 -= learning_rate * db2\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "    \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.301905978634461\n",
      "Epoch 100, Loss: 0.8962600999874162\n",
      "Epoch 200, Loss: 0.7324050087507203\n"
     ]
    }
   ],
   "source": [
    "# Par谩metros de la red\n",
    "input_size = 784  # Tama帽o de la entrada (28x28 p铆xeles)\n",
    "hidden_size = 128  # N煤mero de neuronas en la capa oculta\n",
    "output_size = 10  # N煤mero de clases (diez categor铆as de ropa)\n",
    "epochs = 300  # N煤mero de 茅pocas\n",
    "learning_rate = 0.1  # Tasa de aprendizaje\n",
    "\n",
    "# Entrenar el modelo\n",
    "W1, b1, W2, b2 = train(X_train, y_train, input_size, hidden_size, output_size, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Evaluaci贸n del Modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.41%\n"
     ]
    }
   ],
   "source": [
    "# Test para verificar que todo funciona\n",
    "A1, A2 = forward_pass(X_test, W1, b1, W2, b2)\n",
    "predictions = np.argmax(A2, axis=1)\n",
    "\n",
    "# Calcular la precisi贸n\n",
    "accuracy = np.mean(predictions == np.argmax(y_test, axis=1)) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusi贸n\n",
    "He implementado una red neuronal desde cero para clasificar im谩genes del dataset Fashion MNIST. He preprocesado los datos, definido las funciones necesarias para la red neuronal, entrenado el modelo y evaluado su precisi贸n. Este proyecto ha permitido comprender los conceptos fundamentales de las redes neuronales, incluyendo la normalizaci贸n de datos, la codificaci贸n One-Hot, el pase hacia adelante, la funci贸n de p茅rdida y la retropropagaci贸n. La precisi贸n obtenida del modelo es del 77.41%, lo cual es un buen punto de partida para futuras mejoras y optimizaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
